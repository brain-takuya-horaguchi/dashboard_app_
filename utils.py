import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import json
import openai
import streamlit as st
import os
from dotenv import load_dotenv
import chardet
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()


def detect_encoding(file_bytes: bytes) -> str:
    """
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è‡ªå‹•æ¤œå‡ºã™ã‚‹é–¢æ•°
    """
    # ã‚ˆãä½¿ã‚ã‚Œã‚‹æ—¥æœ¬èªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒªã‚¹ãƒˆ
    encodings = ['utf-8', 'shift_jis', 'cp932', 'euc-jp', 'iso-2022-jp']
    
    # chardetã‚’ä½¿ç”¨ã—ã¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ¤œå‡º
    detected = chardet.detect(file_bytes)
    if detected and detected['encoding']:
        # æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å„ªå…ˆçš„ã«è©¦ã™
        detected_encoding = detected['encoding'].lower()
        if detected_encoding in encodings:
            encodings.insert(0, detected_encoding)
    
    # å„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦ã™
    for encoding in encodings:
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®å…ˆé ­éƒ¨åˆ†ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦ãƒ†ã‚¹ãƒˆ
            file_bytes[:10000].decode(encoding)
            return encoding
        except (UnicodeDecodeError, LookupError):
            continue
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã—ã¦UTF-8ã‚’è¿”ã™
    return 'utf-8'


def read_csv_with_encoding(uploaded_file) -> pd.DataFrame:
    """
    ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è‡ªå‹•æ¤œå‡ºã—ã¦CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
    """
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚¤ãƒˆã¨ã—ã¦èª­ã¿è¾¼ã‚€
    file_bytes = uploaded_file.read()
    uploaded_file.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
    
    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ¤œå‡º
    encoding = detect_encoding(file_bytes)
    
    # æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§CSVã‚’èª­ã¿è¾¼ã‚€
    try:
        df = pd.read_csv(uploaded_file, encoding=encoding)
        return df
    except Exception as e:
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œå‡ºãŒå¤±æ•—ã—ãŸå ´åˆã€ã‚ˆãä½¿ã‚ã‚Œã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’é †ã«è©¦ã™
        encodings = ['utf-8', 'shift_jis', 'cp932', 'euc-jp', 'latin-1']
        for enc in encodings:
            try:
                uploaded_file.seek(0)
                df = pd.read_csv(uploaded_file, encoding=enc)
                return df
            except:
                continue
        # ã™ã¹ã¦å¤±æ•—ã—ãŸå ´åˆã¯ã‚¨ãƒ©ãƒ¼ã‚’å†ç™ºç”Ÿ
        raise Exception(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®æ¤œå‡ºãŒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼: {str(e)}")

def validate_data(df: pd.DataFrame) -> Dict:
    """
    ãƒ‡ãƒ¼ã‚¿ã®å“è³ªã‚’æ¤œè¨¼ã™ã‚‹é–¢æ•°
    """
    validation_results = {
        'is_valid': True,
        'errors': [],
        'warnings': [],
        'statistics': {}
    }
    
    required_columns = [
        'æ±‚è·è€…ï¼šæ±‚è·è€…ID', 'ä¼æ¥­ï¼šä¼æ¥­å', 'é€²æ—ï¼šæ›¸é¡æå‡ºæ—¥', 
        'é€²æ—ï¼šé¢æ¥æ—¥', 'é€²æ—ï¼šé¢æ¥å›æ•°', 'é€²æ—ï¼šæœ€çµ‚é¢æ¥ãƒ•ãƒ©ã‚°', 
        'é€²æ—ï¼šå†…å®šæ—¥', 'é€²æ—ï¼šã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'
    ]
    
    # å¿…é ˆã‚«ãƒ©ãƒ ã®ç¢ºèª
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        validation_results['errors'].append(f"å¿…é ˆåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing_columns)}")
        validation_results['is_valid'] = False
    
    if not validation_results['is_valid']:
        return validation_results
    
    # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
    total_rows = len(df)
    
    # 1. ç©ºãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
    if total_rows == 0:
        validation_results['errors'].append("ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
        validation_results['is_valid'] = False
        return validation_results
    
    # 2. é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
    duplicates = df.duplicated().sum()
    if duplicates > 0:
        validation_results['warnings'].append(f"é‡è¤‡è¡ŒãŒ {duplicates} ä»¶ã‚ã‚Šã¾ã™")
    
    # 3. æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ç¢ºèª
    date_columns = ['é€²æ—ï¼šæ›¸é¡æå‡ºæ—¥', 'é€²æ—ï¼šé¢æ¥æ—¥', 'é€²æ—ï¼šå†…å®šæ—¥']
    for col in date_columns:
        invalid_dates = 0
        for val in df[col].dropna():
            try:
                pd.to_datetime(val)
            except:
                invalid_dates += 1
        
        if invalid_dates > 0:
            validation_results['warnings'].append(f"{col} ã«ç„¡åŠ¹ãªæ—¥ä»˜ãŒ {invalid_dates} ä»¶ã‚ã‚Šã¾ã™")
    
    # 4. é¢æ¥å›æ•°ã®ç¢ºèª
    invalid_interview_counts = df[df['é€²æ—ï¼šé¢æ¥å›æ•°'].notna() & (df['é€²æ—ï¼šé¢æ¥å›æ•°'] < 0)].shape[0]
    if invalid_interview_counts > 0:
        validation_results['warnings'].append(f"é¢æ¥å›æ•°ãŒè² ã®å€¤ã®è¡ŒãŒ {invalid_interview_counts} ä»¶ã‚ã‚Šã¾ã™")
    
    # 5. æœ€çµ‚é¢æ¥ãƒ•ãƒ©ã‚°ã®ç¢ºèª
    invalid_final_flags = df[df['é€²æ—ï¼šæœ€çµ‚é¢æ¥ãƒ•ãƒ©ã‚°'].notna() & 
                           (~df['é€²æ—ï¼šæœ€çµ‚é¢æ¥ãƒ•ãƒ©ã‚°'].isin([0, 1]))].shape[0]
    if invalid_final_flags > 0:
        validation_results['warnings'].append(f"æœ€çµ‚é¢æ¥ãƒ•ãƒ©ã‚°ãŒ0ã¾ãŸã¯1ä»¥å¤–ã®è¡ŒãŒ {invalid_final_flags} ä»¶ã‚ã‚Šã¾ã™")
    
    # çµ±è¨ˆæƒ…å ±
    validation_results['statistics'] = {
        'total_rows': total_rows,
        'unique_candidates': df['æ±‚è·è€…ï¼šæ±‚è·è€…ID'].nunique(),
        'unique_companies': df['ä¼æ¥­ï¼šä¼æ¥­å'].nunique(),
        'data_completeness': {
            'æ›¸é¡æå‡ºæ—¥': (df['é€²æ—ï¼šæ›¸é¡æå‡ºæ—¥'].notna().sum() / total_rows * 100),
            'é¢æ¥æ—¥': (df['é€²æ—ï¼šé¢æ¥æ—¥'].notna().sum() / total_rows * 100),
            'å†…å®šæ—¥': (df['é€²æ—ï¼šå†…å®šæ—¥'].notna().sum() / total_rows * 100)
        }
    }
    
    return validation_results


def generate_alerts(metrics_df: pd.DataFrame) -> List[Dict]:
    """
    ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã«åŸºã¥ã„ã¦ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
    """
    alerts = []
    
    if metrics_df.empty:
        return alerts
    
    # 1. ä½å†…å®šç‡ã‚¢ãƒ©ãƒ¼ãƒˆ
    low_success_rate = metrics_df[metrics_df['å†…å®šç‡'] < 5]
    if not low_success_rate.empty:
        for _, company in low_success_rate.iterrows():
            alerts.append({
                'type': 'danger',
                'title': 'ğŸš¨ ç·Šæ€¥: æ¥µä½å†…å®šç‡',
                'company': company['ä¼æ¥­å'],
                'message': f"å†…å®šç‡ãŒ {company['å†…å®šç‡']:.1f}% ã¨æ¥µç«¯ã«ä½ã„çŠ¶æ³ã§ã™ã€‚å³åº§ã®å¯¾ç­–ãŒå¿…è¦ã§ã™ã€‚",
                'priority': 'high'
            })
    
    # 2. é•·æœŸå‡¦ç†æ™‚é–“ã‚¢ãƒ©ãƒ¼ãƒˆ
    slow_processing = metrics_df[metrics_df['å¹³å‡å‡¦ç†æ™‚é–“'] > 60]
    if not slow_processing.empty:
        for _, company in slow_processing.iterrows():
            alerts.append({
                'type': 'warning',
                'title': 'â° é•·æœŸå‡¦ç†æ™‚é–“',
                'company': company['ä¼æ¥­å'],
                'message': f"å¹³å‡å‡¦ç†æ™‚é–“ãŒ {company['å¹³å‡å‡¦ç†æ™‚é–“']} æ—¥ã¨é•·æœŸåŒ–ã—ã¦ã„ã¾ã™ã€‚ãƒ—ãƒ­ã‚»ã‚¹ã®è¦‹ç›´ã—ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚",
                'priority': 'medium'
            })
    
    # 3. æ›¸é¡é€šéç‡ç•°å¸¸ã‚¢ãƒ©ãƒ¼ãƒˆ
    low_document_rate = metrics_df[
        (metrics_df['æ›¸é¡æå‡ºæ•°'] > 5) & 
        (metrics_df['æ›¸é¡é€šéç‡'] < 10)
    ]
    if not low_document_rate.empty:
        for _, company in low_document_rate.iterrows():
            alerts.append({
                'type': 'warning',
                'title': 'ğŸ“„ æ›¸é¡é€šéç‡ä½ä¸‹',
                'company': company['ä¼æ¥­å'],
                'message': f"æ›¸é¡é€šéç‡ãŒ {company['æ›¸é¡é€šéç‡']:.1f}% ã¨ä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚å¿œå‹Ÿæ›¸é¡ã®è³ªå‘ä¸ŠãŒå¿…è¦ã§ã™ã€‚",
                'priority': 'medium'
            })
    
    # 4. é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¢ãƒ©ãƒ¼ãƒˆï¼ˆè‰¯ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼‰
    high_performers = metrics_df[
        (metrics_df['å†…å®šç‡'] > 30) & 
        (metrics_df['å†…å®šæ•°'] > 2)
    ]
    if not high_performers.empty:
        for _, company in high_performers.iterrows():
            alerts.append({
                'type': 'success',
                'title': 'ğŸ‰ é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹',
                'company': company['ä¼æ¥­å'],
                'message': f"å†…å®šç‡ {company['å†…å®šç‡']:.1f}% ã®å„ªç§€ãªæˆæœã‚’è¨˜éŒ²ã—ã¦ã„ã¾ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä»–ç¤¾ã«ã‚‚å±•é–‹æ¤œè¨ã—ã¦ãã ã•ã„ã€‚",
                'priority': 'low'
            })
    
    # 5. ãƒ‡ãƒ¼ã‚¿ç•°å¸¸ã‚¢ãƒ©ãƒ¼ãƒˆ
    data_anomalies = metrics_df[
        (metrics_df['æ›¸é¡æå‡ºæ•°'] > 0) & 
        (metrics_df['1æ¬¡é¢æ¥æ•°'] > metrics_df['æ›¸é¡æå‡ºæ•°'])
    ]
    if not data_anomalies.empty:
        for _, company in data_anomalies.iterrows():
            alerts.append({
                'type': 'info',
                'title': 'ğŸ“Š ãƒ‡ãƒ¼ã‚¿ç•°å¸¸',
                'company': company['ä¼æ¥­å'],
                'message': "1æ¬¡é¢æ¥æ•°ãŒæ›¸é¡æå‡ºæ•°ã‚’ä¸Šå›ã£ã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªãŒå¿…è¦ã§ã™ã€‚",
                'priority': 'low'
            })
    
    # å„ªå…ˆåº¦é †ã§ã‚½ãƒ¼ãƒˆ
    priority_order = {'high': 0, 'medium': 1, 'low': 2}
    alerts.sort(key=lambda x: priority_order[x['priority']])
    
    return alerts


def generate_recommendations(metrics_df: pd.DataFrame) -> List[Dict]:
    """
    ãƒ‡ãƒ¼ã‚¿åˆ†æçµæœã«åŸºã¥ã„ã¦æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
    """
    recommendations = []
    
    if metrics_df.empty:
        return recommendations
    
    # 1. æ›¸é¡é¸è€ƒæ”¹å–„ææ¡ˆ
    low_doc_pass_rate = metrics_df[metrics_df['æ›¸é¡é€šéç‡'] < 20]
    if not low_doc_pass_rate.empty:
        recommendations.append({
            'category': 'æ›¸é¡é¸è€ƒ',
            'title': 'ğŸ“„ æ›¸é¡é¸è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®æ”¹å–„',
            'description': 'æ›¸é¡é€šéç‡ãŒä½ã„ä¼æ¥­ãŒã‚ã‚Šã¾ã™ã€‚',
            'actions': [
                'å¿œå‹Ÿæ›¸é¡ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¦‹ç›´ã™',
                'ä¼æ¥­ã®ãƒ‹ãƒ¼ã‚ºã«åˆã‚ã›ãŸæ›¸é¡ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º',
                'æ›¸é¡ä½œæˆç ”ä¿®ã®å®Ÿæ–½',
                'éå»ã®æˆåŠŸäº‹ä¾‹ã‚’åˆ†æã—ã¦å…±æœ‰'
            ],
            'target_companies': low_doc_pass_rate['ä¼æ¥­å'].tolist()
        })
    
    # 2. é¢æ¥å¯¾ç­–ææ¡ˆ
    low_interview_pass_rate = metrics_df[metrics_df['1æ¬¡é¢æ¥é€šéç‡'] < 30]
    if not low_interview_pass_rate.empty:
        recommendations.append({
            'category': 'é¢æ¥å¯¾ç­–',
            'title': 'ğŸ¯ é¢æ¥å¯¾ç­–ã®å¼·åŒ–',
            'description': '1æ¬¡é¢æ¥é€šéç‡ãŒä½ã„ä¼æ¥­ãŒã‚ã‚Šã¾ã™ã€‚',
            'actions': [
                'æ¨¡æ“¬é¢æ¥ã®å®Ÿæ–½',
                'ä¼æ¥­ç ”ç©¶ã®å¾¹åº•',
                'é¢æ¥å®˜ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†',
                'é¢æ¥ã‚¹ã‚­ãƒ«å‘ä¸Šç ”ä¿®ã®å®Ÿæ–½'
            ],
            'target_companies': low_interview_pass_rate['ä¼æ¥­å'].tolist()
        })
    
    # 3. å‡¦ç†æ™‚é–“çŸ­ç¸®ææ¡ˆ
    slow_companies = metrics_df[metrics_df['å¹³å‡å‡¦ç†æ™‚é–“'] > 45]
    if not slow_companies.empty:
        recommendations.append({
            'category': 'åŠ¹ç‡åŒ–',
            'title': 'âš¡ å‡¦ç†æ™‚é–“ã®çŸ­ç¸®',
            'description': 'é¸è€ƒãƒ—ãƒ­ã‚»ã‚¹ãŒé•·æœŸåŒ–ã—ã¦ã„ã‚‹ä¼æ¥­ãŒã‚ã‚Šã¾ã™ã€‚',
            'actions': [
                'ä¼æ¥­ã¨ã®å®šæœŸçš„ãªé€²æ—ç¢ºèª',
                'é¸è€ƒã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æœ€é©åŒ–',
                'ä¸­é–“ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã®å®Ÿæ–½',
                'ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–ã«ã‚ˆã‚‹åŠ¹ç‡åŒ–'
            ],
            'target_companies': slow_companies['ä¼æ¥­å'].tolist()
        })
    
    # 4. æˆåŠŸäº‹ä¾‹ã®æ¨ªå±•é–‹ææ¡ˆ
    top_performers = metrics_df.nlargest(3, 'å†…å®šç‡')
    if not top_performers.empty:
        recommendations.append({
            'category': 'æˆåŠŸäº‹ä¾‹',
            'title': 'ğŸ† æˆåŠŸäº‹ä¾‹ã®æ¨ªå±•é–‹',
            'description': 'é«˜ã„æˆæœã‚’å‡ºã—ã¦ã„ã‚‹ä¼æ¥­ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä»–ç¤¾ã«ã‚‚é©ç”¨ã§ãã¾ã™ã€‚',
            'actions': [
                'æˆåŠŸä¼æ¥­ã®ãƒ—ãƒ­ã‚»ã‚¹åˆ†æ',
                'ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã®æ–‡æ›¸åŒ–',
                'ä»–ç¤¾ã¸ã®é©ç”¨å¯èƒ½æ€§æ¤œè¨',
                'æˆåŠŸè¦å› ã®å…±æœ‰ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Ÿæ–½'
            ],
            'target_companies': top_performers['ä¼æ¥­å'].tolist()
        })
    
    return recommendations


def calculate_conversion_funnel(df: pd.DataFrame, company_name: str = None) -> Dict:
    """
    ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ•ã‚¡ãƒãƒ«ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
    """
    if company_name:
        df = df[df['ä¼æ¥­ï¼šä¼æ¥­å'] == company_name]
    
    if df.empty:
        return {
            'funnel': {},
            'conversion_rates': {}
        }
    
    # å„æ®µéšã®æ•°ã‚’è¨ˆç®—
    funnel = {
        'æ¨è–¦': df['æ±‚è·è€…ï¼šæ±‚è·è€…ID'].nunique(),
        'æ›¸é¡æå‡º': df['é€²æ—ï¼šæ›¸é¡æå‡ºæ—¥'].notna().sum(),
        'æ›¸é¡é€šé': df['é€²æ—ï¼šé¢æ¥æ—¥'].notna().sum(),
        '1æ¬¡é¢æ¥': df[(df['é€²æ—ï¼šé¢æ¥å›æ•°'] >= 1) & (df['é€²æ—ï¼šé¢æ¥æ—¥'].notna())].shape[0],
        '2æ¬¡é¢æ¥ä»¥é™': df[(df['é€²æ—ï¼šé¢æ¥å›æ•°'] > 1) & (df['é€²æ—ï¼šé¢æ¥æ—¥'].notna())].shape[0],
        'æœ€çµ‚é¢æ¥': df[(df['é€²æ—ï¼šæœ€çµ‚é¢æ¥ãƒ•ãƒ©ã‚°'] == 1) & (df['é€²æ—ï¼šé¢æ¥æ—¥'].notna())].shape[0],
        'å†…å®š': df['é€²æ—ï¼šå†…å®šæ—¥'].notna().sum()
    }
    
    # é€šéç‡ã‚’è¨ˆç®—ï¼ˆå„æ®µéšé–“ã®é€šéç‡ï¼‰
    conversion_rates = {}
    
    # å­˜åœ¨ã™ã‚‹æ®µéšã®ã¿ã‚’å¯¾è±¡ã«é€šéç‡ã‚’è¨ˆç®—
    stage_pairs = [
        ('æ¨è–¦', 'æ›¸é¡æå‡º'),
        ('æ›¸é¡æå‡º', 'æ›¸é¡é€šé'),
        ('æ›¸é¡é€šé', '1æ¬¡é¢æ¥'),
        ('1æ¬¡é¢æ¥', '2æ¬¡é¢æ¥ä»¥é™'),
        ('2æ¬¡é¢æ¥ä»¥é™', 'æœ€çµ‚é¢æ¥'),
        ('æœ€çµ‚é¢æ¥', 'å†…å®š')
    ]
    
    for from_stage, to_stage in stage_pairs:
        if from_stage in funnel and to_stage in funnel and funnel[from_stage] > 0:
            conversion_rates[f"{from_stage}â†’{to_stage}"] = (funnel[to_stage] / funnel[from_stage]) * 100
    
    # è¡¨ç¤ºç”¨ã«ãƒ•ã‚¡ãƒãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰0ã®å€¤ã‚’å‰Šé™¤
    funnel = {k: v for k, v in funnel.items() if v > 0}
    
    return {
        'funnel': funnel,
        'conversion_rates': conversion_rates
    }


def export_summary_report(metrics_df: pd.DataFrame, alerts: List[Dict], recommendations: List[Dict]) -> str:
    """
    ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
    """
    try:
        if metrics_df.empty:
            return "# ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™\n\nåˆ†æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        # åŸºæœ¬çµ±è¨ˆã®è¨ˆç®—
        total_companies = len(metrics_df)
        total_recommendations = int(metrics_df['æ¨è–¦äººæ•°'].sum())
        total_applications = int(metrics_df['æ›¸é¡æå‡ºæ•°'].sum())
        total_offers = int(metrics_df['å†…å®šæ•°'].sum())
        
        # å†…å®šç‡ã®è¨ˆç®—ï¼ˆã‚¼ãƒ­é™¤ç®—ã‚’å›é¿ï¼‰
        overall_rate = (total_offers / total_recommendations * 100) if total_recommendations > 0 else 0
        
        report = f"""# ä¼æ¥­æ¡ç”¨åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}

## ğŸ“Š å…¨ä½“ã‚µãƒãƒªãƒ¼
- åˆ†æå¯¾è±¡ä¼æ¥­æ•°: {total_companies}
- ç·æ¨è–¦äººæ•°: {total_recommendations:,}
- ç·æ›¸é¡æå‡ºæ•°: {total_applications:,}
- ç·å†…å®šæ•°: {total_offers:,}
- å…¨ä½“å†…å®šç‡: {overall_rate:.1f}%

## ğŸ¯ ãƒˆãƒƒãƒ—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ¼
"""
        
        # ä¸Šä½3ç¤¾ã®å‡¦ç†
        if len(metrics_df) > 0:
            top_3 = metrics_df.nlargest(min(3, len(metrics_df)), 'å†…å®šç‡')
            for i, (_, company) in enumerate(top_3.iterrows(), 1):
                report += f"{i}. {company['ä¼æ¥­å']}: å†…å®šç‡ {company['å†…å®šç‡']:.1f}%\n"
        else:
            report += "ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚\n"
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆã®å‡¦ç†
        report += "\n## ğŸš¨ ã‚¢ãƒ©ãƒ¼ãƒˆ\n"
        if alerts:
            high_priority_alerts = [a for a in alerts if a.get('priority') == 'high']
            if high_priority_alerts:
                for alert in high_priority_alerts:
                    company = alert.get('company', 'ä¸æ˜')
                    title = alert.get('title', 'ä¸æ˜')
                    message = alert.get('message', 'ä¸æ˜')
                    report += f"- {title}: {company} - {message}\n"
            else:
                report += "- ç·Šæ€¥ã®ã‚¢ãƒ©ãƒ¼ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“\n"
        else:
            report += "- ã‚¢ãƒ©ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“\n"
        
        # æ”¹å–„ææ¡ˆã®å‡¦ç†
        report += "\n## ğŸ’¡ æ”¹å–„ææ¡ˆ\n"
        if recommendations:
            for rec in recommendations:
                title = rec.get('title', 'ä¸æ˜')
                description = rec.get('description', 'ä¸æ˜')
                actions = rec.get('actions', [])
                target_companies = rec.get('target_companies', [])
                
                report += f"### {title}\n"
                report += f"{description}\n"
                for action in actions:
                    report += f"- {action}\n"
                
                if target_companies:
                    companies_str = ', '.join(target_companies[:3])
                    if len(target_companies) > 3:
                        companies_str += f" ãªã© {len(target_companies)} ç¤¾"
                    report += f"å¯¾è±¡ä¼æ¥­: {companies_str}\n\n"
                else:
                    report += "å¯¾è±¡ä¼æ¥­: ãªã—\n\n"
        else:
            report += "- æ”¹å–„ææ¡ˆã¯ã‚ã‚Šã¾ã›ã‚“\n"
        
        # çµ±è¨ˆæƒ…å ±ã®è¿½åŠ 
        report += "\n## ğŸ“ˆ çµ±è¨ˆæƒ…å ±\n"
        if len(metrics_df) > 0:
            report += f"- æœ€é«˜å†…å®šç‡: {metrics_df['å†…å®šç‡'].max():.1f}%\n"
            report += f"- æœ€ä½å†…å®šç‡: {metrics_df['å†…å®šç‡'].min():.1f}%\n"
            report += f"- å¹³å‡å†…å®šç‡: {metrics_df['å†…å®šç‡'].mean():.1f}%\n"
            report += f"- å¹³å‡æ›¸é¡é€šéç‡: {metrics_df['æ›¸é¡é€šéç‡'].mean():.1f}%\n"
            report += f"- å¹³å‡å‡¦ç†æ™‚é–“: {metrics_df['å¹³å‡å‡¦ç†æ™‚é–“'].mean():.1f}æ—¥\n"
        
        return report
        
    except Exception as e:
        return f"# ã‚¨ãƒ©ãƒ¼: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ\n\nã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}"


def setup_openai_client():
    """OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’è¨­å®š"""
    try:
        # .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
        api_key = os.environ.get("OPENAI_API_KEY")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: Streamlit secretsã¾ãŸã¯session_stateã‹ã‚‰èª­ã¿è¾¼ã‚€
        if not api_key:
            api_key = st.secrets.get("OPENAI_API_KEY") or st.session_state.get("openai_api_key")
        
        if not api_key:
            return None
        
        client = openai.OpenAI(api_key=api_key)
        return client
    except Exception as e:
        st.error(f"OpenAI APIã®è¨­å®šã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None


def create_data_summary(df: pd.DataFrame, metrics_df: pd.DataFrame) -> str:
    """ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆã—ã¦AIã«æä¾›"""
    try:
        # åŸºæœ¬çµ±è¨ˆ
        total_rows = len(df)
        unique_companies = df['ä¼æ¥­ï¼šä¼æ¥­å'].nunique()
        unique_candidates = df['æ±‚è·è€…ï¼šæ±‚è·è€…ID'].nunique()
        
        # ä¼æ¥­ä¸€è¦§ï¼ˆä¸Šä½10ç¤¾ï¼‰
        company_list = df['ä¼æ¥­ï¼šä¼æ¥­å'].value_counts().head(10).to_dict()
        
        # æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ã®è¦ç´„
        metrics_summary = ""
        if not metrics_df.empty:
            metrics_summary = f"""
æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ï¼ˆä¸Šä½5ç¤¾ï¼‰:
{metrics_df.head(5).to_string()}

å…¨ä½“çµ±è¨ˆ:
- ç·æ¨è–¦äººæ•°: {metrics_df['æ¨è–¦äººæ•°'].sum():,}
- ç·æ›¸é¡æå‡ºæ•°: {metrics_df['æ›¸é¡æå‡ºæ•°'].sum():,}
- ç·å†…å®šæ•°: {metrics_df['å†…å®šæ•°'].sum():,}
- å¹³å‡å†…å®šç‡: {metrics_df['å†…å®šç‡'].mean():.1f}%
- å¹³å‡æ›¸é¡é€šéç‡: {metrics_df['æ›¸é¡é€šéç‡'].mean():.1f}%
"""
        
        # æ—¥ä»˜ç¯„å›²
        date_columns = ['é€²æ—ï¼šæ›¸é¡æå‡ºæ—¥', 'é€²æ—ï¼šé¢æ¥æ—¥', 'é€²æ—ï¼šå†…å®šæ—¥']
        date_ranges = {}
        for col in date_columns:
            dates = pd.to_datetime(df[col], errors='coerce').dropna()
            if not dates.empty:
                date_ranges[col] = {
                    'min': dates.min().strftime('%Y-%m-%d'),
                    'max': dates.max().strftime('%Y-%m-%d')
                }
        
        summary = f"""
ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:
- ç·è¡Œæ•°: {total_rows:,}
- ä¼æ¥­æ•°: {unique_companies:,}
- æ±‚è·è€…æ•°: {unique_candidates:,}

ä¸»è¦ä¼æ¥­ (å¿œå‹Ÿä»¶æ•°é †):
{json.dumps(company_list, ensure_ascii=False, indent=2)}

ãƒ‡ãƒ¼ã‚¿æœŸé–“:
{json.dumps(date_ranges, ensure_ascii=False, indent=2)}

{metrics_summary}

ãƒ‡ãƒ¼ã‚¿æ§‹é€ :
- å„è¡Œã¯æ±‚è·è€…ã¨ä¼æ¥­ã®çµ„ã¿åˆã‚ã›ã‚’è¡¨ã™
- é€²æ—ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã€æ›¸é¡æå‡ºæ—¥ã€é¢æ¥æ—¥ã€å†…å®šæ—¥ãªã©ã®æƒ…å ±ã‚’å«ã‚€
- é¢æ¥å›æ•°ã€æœ€çµ‚é¢æ¥ãƒ•ãƒ©ã‚°ãªã©ã®è©³ç´°æƒ…å ±ã‚‚å«ã‚€
"""
        
        return summary
    except Exception as e:
        return f"ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼ã®ä½œæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"


def query_data_with_ai(question: str, df: pd.DataFrame, metrics_df: pd.DataFrame, client) -> str:
    """AIã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹è³ªå•ã«å›ç­”"""
    try:
        # ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ
        data_summary = create_data_summary(df, metrics_df)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
        system_prompt = f"""
ã‚ãªãŸã¯ä¼æ¥­æ¡ç”¨åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æ­£ç¢ºã§æœ‰ç”¨ãªå›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

{data_summary}

å›ç­”ã®éš›ã¯ä»¥ä¸‹ã®ç‚¹ã«æ³¨æ„ã—ã¦ãã ã•ã„:
1. ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸå…·ä½“çš„ãªæ•°å€¤ã‚’ä½¿ç”¨ã™ã‚‹
2. åˆ†æçµæœã‹ã‚‰å®Ÿç”¨çš„ãªæ´å¯Ÿã‚’æä¾›ã™ã‚‹
3. å¯èƒ½ãªå ´åˆã¯æ”¹å–„ææ¡ˆã‚‚å«ã‚ã‚‹
4. æ—¥æœ¬èªã§å›ç­”ã™ã‚‹
5. ä¸æ˜ãªç‚¹ãŒã‚ã‚Œã°ã€ãƒ‡ãƒ¼ã‚¿ã®åˆ¶ç´„ã‚’æ˜ç¢ºã«ã™ã‚‹
"""
        
        user_prompt = f"""
è³ªå•: {question}

ã“ã®è³ªå•ã«ã¤ã„ã¦ã€æä¾›ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚
ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹å…·ä½“çš„ãªæƒ…å ±ã‚„å‚¾å‘ã€ãã—ã¦å®Ÿç”¨çš„ãªæ´å¯Ÿã‚’å«ã‚ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚
"""
        
        # OpenAI APIã‚’å‘¼ã³å‡ºã—
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # gpt-4o-miniã‚’ä½¿ç”¨
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=1000,
            temperature=0.7
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"AIåˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"


def get_suggested_questions(df: pd.DataFrame, metrics_df: pd.DataFrame) -> List[str]:
    """ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦æ¨å¥¨è³ªå•ã‚’ç”Ÿæˆ"""
    suggestions = [
        "æœ€ã‚‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒè‰¯ã„ä¼æ¥­ã¯ã©ã“ã§ã™ã‹ï¼Ÿ",
        "å†…å®šç‡ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æ•™ãˆã¦ãã ã•ã„",
        "æ›¸é¡é€šéç‡ãŒä½ã„ä¼æ¥­ã®ç‰¹å¾´ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "å‡¦ç†æ™‚é–“ãŒé•·ã„ä¼æ¥­ã«ã¤ã„ã¦åˆ†æã—ã¦ãã ã•ã„",
        "æœˆåˆ¥ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
        "ã©ã®ä¼æ¥­ã«æœ€ã‚‚åŠ›ã‚’å…¥ã‚Œã‚‹ã¹ãã§ã™ã‹ï¼Ÿ",
        "é¸è€ƒãƒ—ãƒ­ã‚»ã‚¹ã§æœ€ã‚‚èª²é¡Œã¨ãªã£ã¦ã„ã‚‹æ®µéšã¯ã©ã“ã§ã™ã‹ï¼Ÿ",
        "æˆåŠŸã—ã¦ã„ã‚‹ä¼æ¥­ã®å…±é€šç‚¹ã¯ä½•ã§ã™ã‹ï¼Ÿ"
    ]
    
    # ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸå‹•çš„ãªè³ªå•ã‚’è¿½åŠ 
    if not metrics_df.empty:
        # æœ€ã‚‚å†…å®šç‡ã®é«˜ã„ä¼æ¥­
        best_company = metrics_df.loc[metrics_df['å†…å®šç‡'].idxmax(), 'ä¼æ¥­å']
        suggestions.append(f"{best_company}ãŒæˆåŠŸã—ã¦ã„ã‚‹ç†ç”±ã¯ä½•ã§ã™ã‹ï¼Ÿ")
        
        # æœ€ã‚‚å†…å®šç‡ã®ä½ã„ä¼æ¥­
        worst_company = metrics_df.loc[metrics_df['å†…å®šç‡'].idxmin(), 'ä¼æ¥­å']
        suggestions.append(f"{worst_company}ã®æ”¹å–„ç‚¹ã¯ä½•ã§ã™ã‹ï¼Ÿ")
    
    return suggestions


def save_chat_history(question: str, answer: str):
    """ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ä¿å­˜"""
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    st.session_state.chat_history.append({
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'question': question,
        'answer': answer
    })


def export_chat_history() -> str:
    """ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    try:
        if 'chat_history' not in st.session_state or not st.session_state.chat_history:
            return "# ãƒãƒ£ãƒƒãƒˆå±¥æ­´\n\n**çŠ¶æ…‹**: å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“\n\nè³ªå•ã‚’é€ä¿¡ã—ã¦ã‹ã‚‰ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚"
        
        export_text = f"""# ãƒãƒ£ãƒƒãƒˆå±¥æ­´
ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}
å±¥æ­´ä»¶æ•°: {len(st.session_state.chat_history)} ä»¶

---

"""
        
        for i, chat in enumerate(st.session_state.chat_history, 1):
            timestamp = chat.get('timestamp', 'ä¸æ˜')
            question = chat.get('question', 'è³ªå•ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
            answer = chat.get('answer', 'å›ç­”ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
            
            export_text += f"## è³ªå• {i} ({timestamp})\n\n"
            export_text += f"**ğŸ™‹â€â™€ï¸ è³ªå•:**\n{question}\n\n"
            export_text += f"**ğŸ¤– å›ç­”:**\n{answer}\n\n"
            export_text += "---\n\n"
        
        # çµ±è¨ˆæƒ…å ±ã®è¿½åŠ 
        export_text += f"""## ğŸ“Š çµ±è¨ˆæƒ…å ±
- ç·è³ªå•æ•°: {len(st.session_state.chat_history)}
- æœ€åˆã®è³ªå•: {st.session_state.chat_history[0].get('timestamp', 'ä¸æ˜')}
- æœ€å¾Œã®è³ªå•: {st.session_state.chat_history[-1].get('timestamp', 'ä¸æ˜')}
"""
        
        return export_text
        
    except Exception as e:
        return f"# ã‚¨ãƒ©ãƒ¼: ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ\n\nã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}"


def find_column(df: pd.DataFrame, possible_names: List[str]) -> Optional[str]:
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã§å¯èƒ½ãªã‚«ãƒ©ãƒ åã‚’æ¤œç´¢ã™ã‚‹é–¢æ•°
    """
    for name in possible_names:
        if name in df.columns:
            return name
    return None


def apply_filters(df: pd.DataFrame, selected_companies=None, selected_months=None) -> pd.DataFrame:
    """
    ä¼æ¥­ã¨æœˆã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨ã™ã‚‹é–¢æ•°
    """
    if df.empty:
        return df
    
    # æ—¥ä»˜ã‚«ãƒ©ãƒ ã®ãƒ‘ãƒ¼ã‚¹
    df = df.copy()
    df['æ›¸é¡æå‡ºæ—¥_parsed'] = pd.to_datetime(df['é€²æ—ï¼šæ›¸é¡æå‡ºæ—¥'], errors='coerce')
    df['é¢æ¥æ—¥_parsed'] = pd.to_datetime(df['é€²æ—ï¼šé¢æ¥æ—¥'], errors='coerce')
    df['å†…å®šæ—¥_parsed'] = pd.to_datetime(df['é€²æ—ï¼šå†…å®šæ—¥'], errors='coerce')
    
    # ä¼æ¥­ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆã€Œå…¨ã¦ã€ãŒé¸æŠã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿ï¼‰
    if selected_companies and "å…¨ã¦" not in selected_companies:
        df = df[df['ä¼æ¥­ï¼šä¼æ¥­å'].isin(selected_companies)]
    
    # æœˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆã€Œå…¨ã¦ã€ãŒé¸æŠã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿ï¼‰
    if selected_months and "å…¨ã¦" not in selected_months:
        mask = pd.Series(False, index=df.index)
        for month in selected_months:
            year, month_num = month.split('-')
            year, month_num = int(year), int(month_num)
            
            # æ›¸é¡æå‡ºæ—¥ã€é¢æ¥æ—¥ã€å†…å®šæ—¥ã®ã„ãšã‚Œã‹ãŒæŒ‡å®šæœˆã«å«ã¾ã‚Œã‚‹å ´åˆ
            for date_col in ['æ›¸é¡æå‡ºæ—¥_parsed', 'é¢æ¥æ—¥_parsed', 'å†…å®šæ—¥_parsed']:
                mask |= (df[date_col].dt.year == year) & (df[date_col].dt.month == month_num)
        
        df = df[mask]
    
    return df


def calculate_company_introduction_to_contract_rate(df: pd.DataFrame, selected_companies=None, selected_months=None) -> pd.DataFrame:
    """
    ä¼æ¥­ã”ã¨ã®ç´¹ä»‹ï½æˆç´„ç‡ã‚’è¨ˆç®—
    æˆç´„ = å†…å®šã¨ä»®å®š
    ç´¹ä»‹ = å¿œå‹ŸOKæ—¥ãŒã‚ã‚‹æ±‚è·è€…ã€ã¾ãŸã¯æ¨è–¦ã•ã‚ŒãŸæ±‚è·è€…ï¼ˆå¿œå‹ŸOKæ—¥ãŒãªã„å ´åˆã¯æ¨è–¦äººæ•°ï¼‰
    """
    if df.empty:
        return pd.DataFrame()
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨
    df = apply_filters(df, selected_companies, selected_months)
    
    if df.empty:
        return pd.DataFrame()
    
    # æ—¥ä»˜ã®ãƒ‘ãƒ¼ã‚¹
    df['å†…å®šæ—¥_parsed'] = pd.to_datetime(df['é€²æ—ï¼šå†…å®šæ—¥'], errors='coerce')
    df['å¿œå‹ŸOKæ—¥_parsed'] = pd.to_datetime(df['é€²æ—ï¼šå¿œå‹ŸOKæ—¥'], errors='coerce')
    
    company_stats = []
    for company in df['ä¼æ¥­ï¼šä¼æ¥­å'].unique():
        company_data = df[df['ä¼æ¥­ï¼šä¼æ¥­å'] == company]
        
        # ç´¹ä»‹æ•°: å¿œå‹ŸOKæ—¥ãŒã‚ã‚‹æ±‚è·è€…æ•°ã€ãªã‘ã‚Œã°æ¨è–¦äººæ•°ï¼ˆãƒ¦ãƒ‹ãƒ¼ã‚¯ãªæ±‚è·è€…IDæ•°ï¼‰
        if 'é€²æ—ï¼šå¿œå‹ŸOKæ—¥' in df.columns:
            ç´¹ä»‹æ•° = company_data[company_data['å¿œå‹ŸOKæ—¥_parsed'].notna()]['æ±‚è·è€…ï¼šæ±‚è·è€…ID'].nunique()
            if ç´¹ä»‹æ•° == 0:
                # å¿œå‹ŸOKæ—¥ãŒãªã„å ´åˆã¯æ¨è–¦äººæ•°ã‚’ä½¿ç”¨
                ç´¹ä»‹æ•° = company_data['æ±‚è·è€…ï¼šæ±‚è·è€…ID'].nunique()
        else:
            ç´¹ä»‹æ•° = company_data['æ±‚è·è€…ï¼šæ±‚è·è€…ID'].nunique()  # æ¨è–¦äººæ•° = ç´¹ä»‹æ•°
        
        æˆç´„æ•° = company_data['å†…å®šæ—¥_parsed'].notna().sum()  # å†…å®šæ•° = æˆç´„æ•°
        æˆç´„ç‡ = (æˆç´„æ•° / ç´¹ä»‹æ•° * 100) if ç´¹ä»‹æ•° > 0 else 0.0
        
        company_stats.append({
            'ä¼æ¥­å': company,
            'ç´¹ä»‹æ•°': ç´¹ä»‹æ•°,
            'æˆç´„æ•°': æˆç´„æ•°,
            'æˆç´„ç‡': æˆç´„ç‡
        })
    
    return pd.DataFrame(company_stats)


def calculate_job_introduction_to_contract_rate(df: pd.DataFrame, selected_companies=None, selected_months=None) -> pd.DataFrame:
    """
    æ±‚äººã”ã¨ã®ç´¹ä»‹ï½æˆç´„ç‡ã‚’è¨ˆç®—
    æ±‚äººIDãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã€ä¼æ¥­å+æ±‚è·è€…IDã®çµ„ã¿åˆã‚ã›ã§ä»£æ›¿
    """
    if df.empty:
        return pd.DataFrame()
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨
    df = apply_filters(df, selected_companies, selected_months)
    
    if df.empty:
        return pd.DataFrame()
    
    # æ±‚äººIDã‚«ãƒ©ãƒ ã‚’æ¢ã™
    job_id_col = find_column(df, ['æ±‚äººï¼šæ±‚äººID', 'æ±‚äººID', 'æ±‚äººï¼šID', 'job_id', 'JobID'])
    
    if job_id_col:
        # æ±‚äººIDãŒå­˜åœ¨ã™ã‚‹å ´åˆ
        df['å†…å®šæ—¥_parsed'] = pd.to_datetime(df['é€²æ—ï¼šå†…å®šæ—¥'], errors='coerce')
        df['å¿œå‹ŸOKæ—¥_parsed'] = pd.to_datetime(df['é€²æ—ï¼šå¿œå‹ŸOKæ—¥'], errors='coerce')
        
        job_stats = []
        for job_id in df[job_id_col].dropna().unique():
            job_data = df[df[job_id_col] == job_id]
            
            # ç´¹ä»‹æ•°: å¿œå‹ŸOKæ—¥ãŒã‚ã‚‹æ±‚è·è€…æ•°ã€ãªã‘ã‚Œã°æ¨è–¦äººæ•°
            if 'é€²æ—ï¼šå¿œå‹ŸOKæ—¥' in df.columns:
                ç´¹ä»‹æ•° = job_data[job_data['å¿œå‹ŸOKæ—¥_parsed'].notna()]['æ±‚è·è€…ï¼šæ±‚è·è€…ID'].nunique()
                if ç´¹ä»‹æ•° == 0:
                    ç´¹ä»‹æ•° = job_data['æ±‚è·è€…ï¼šæ±‚è·è€…ID'].nunique()
            else:
                ç´¹ä»‹æ•° = job_data['æ±‚è·è€…ï¼šæ±‚è·è€…ID'].nunique()
            
            æˆç´„æ•° = job_data['å†…å®šæ—¥_parsed'].notna().sum()
            æˆç´„ç‡ = (æˆç´„æ•° / ç´¹ä»‹æ•° * 100) if ç´¹ä»‹æ•° > 0 else 0.0
            
            job_stats.append({
                'æ±‚äººID': job_id,
                'ç´¹ä»‹æ•°': ç´¹ä»‹æ•°,
                'æˆç´„æ•°': æˆç´„æ•°,
                'æˆç´„ç‡': æˆç´„ç‡
            })
        
        return pd.DataFrame(job_stats)
    else:
        # æ±‚äººIDãŒå­˜åœ¨ã—ãªã„å ´åˆã€ä¼æ¥­åã§ä»£æ›¿
        return calculate_company_introduction_to_contract_rate(df, selected_companies, selected_months)


def calculate_avg_recommendations_per_candidate(df: pd.DataFrame, selected_companies=None, selected_months=None) -> Dict:
    """
    æ±‚è·è€…1äººå½“ãŸã‚Šã®å¹³å‡æ¨è–¦æ•°ã‚’è¨ˆç®—
    """
    if df.empty:
        return {'avg_recommendations': 0, 'total_candidates': 0, 'total_recommendations': 0}
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨
    df = apply_filters(df, selected_companies, selected_months)
    
    if df.empty:
        return {'avg_recommendations': 0, 'total_candidates': 0, 'total_recommendations': 0}
    
    total_candidates = df['æ±‚è·è€…ï¼šæ±‚è·è€…ID'].nunique()
    total_recommendations = len(df)
    avg_recommendations = total_recommendations / total_candidates if total_candidates > 0 else 0
    
    return {
        'avg_recommendations': avg_recommendations,
        'total_candidates': total_candidates,
        'total_recommendations': total_recommendations
    }


def calculate_interview_to_recommendation_leadtime(df: pd.DataFrame, selected_companies=None, selected_months=None) -> pd.DataFrame:
    """
    é¢è«‡ã‹ã‚‰æ¨è–¦ã¾ã§ã®ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã‚’è¨ˆç®—
    é¢è«‡æ—¥ã¨æ¨è–¦æ—¥ï¼ˆæ›¸é¡æå‡ºæ—¥ï¼‰ã®å·®ã‚’è¨ˆç®—
    """
    if df.empty:
        return pd.DataFrame()
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨
    df = apply_filters(df, selected_companies, selected_months)
    
    if df.empty:
        return pd.DataFrame()
    
    # é¢è«‡æ—¥ã‚«ãƒ©ãƒ ã‚’æ¢ã™ï¼ˆå®Ÿéš›ã®ã‚«ãƒ©ãƒ åã«åˆã‚ã›ã‚‹ï¼‰
    interview_date_col = find_column(df, [
        'æ±‚è·è€…ï¼šé¢è«‡æ—¥',  # å®Ÿéš›ã®ã‚«ãƒ©ãƒ å
        'é¢è«‡ï¼šé¢è«‡æ—¥', 'é¢è«‡æ—¥', 'é¢è«‡ï¼šæ—¥ä»˜', 'interview_date', 
        'é¢è«‡ï¼šå®Ÿæ–½æ—¥', 'CAï¼šé¢è«‡æ—¥', 'æ±‚è·è€…ï¼šé›»è©±é¢è«‡æ—¥'
    ])
    
    # æ¨è–¦æ—¥ = æ›¸é¡æå‡ºæ—¥ã¨ä»®å®š
    df['æ¨è–¦æ—¥_parsed'] = pd.to_datetime(df['é€²æ—ï¼šæ›¸é¡æå‡ºæ—¥'], errors='coerce')
    
    if interview_date_col:
        df['é¢è«‡æ—¥_parsed'] = pd.to_datetime(df[interview_date_col], errors='coerce')
        
        # ä¸¡æ–¹ã®æ—¥ä»˜ãŒå­˜åœ¨ã™ã‚‹è¡Œã®ã¿
        valid_data = df[(df['é¢è«‡æ—¥_parsed'].notna()) & (df['æ¨è–¦æ—¥_parsed'].notna())].copy()
        
        if not valid_data.empty:
            valid_data['ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ '] = (valid_data['æ¨è–¦æ—¥_parsed'] - valid_data['é¢è«‡æ—¥_parsed']).dt.days
            
            leadtime_stats = []
            for company in valid_data['ä¼æ¥­ï¼šä¼æ¥­å'].unique():
                company_data = valid_data[valid_data['ä¼æ¥­ï¼šä¼æ¥­å'] == company]
                avg_leadtime = company_data['ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ '].mean()
                
                leadtime_stats.append({
                    'ä¼æ¥­å': company,
                    'å¹³å‡ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ': avg_leadtime,
                    'ä»¶æ•°': len(company_data)
                })
            
            return pd.DataFrame(leadtime_stats)
    
    return pd.DataFrame()


def calculate_interviews_by_ca(df: pd.DataFrame, selected_companies=None, selected_months=None) -> pd.DataFrame:
    """
    CAã”ã¨ã®é¢è«‡æ•°ã‚’è¨ˆç®—
    """
    if df.empty:
        return pd.DataFrame()
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨
    df = apply_filters(df, selected_companies, selected_months)
    
    if df.empty:
        return pd.DataFrame()
    
    # CAã‚«ãƒ©ãƒ ã‚’æ¢ã™ï¼ˆå®Ÿéš›ã®ã‚«ãƒ©ãƒ åã«åˆã‚ã›ã‚‹ï¼‰
    ca_col = find_column(df, [
        'æ±‚è·è€…ï¼šæ‹…å½“è€…',  # å®Ÿéš›ã®ã‚«ãƒ©ãƒ å
        'CAï¼šCAå', 'CAå', 'CAï¼šåå‰', 'CA', 'ca_name', 'CAï¼šæ‹…å½“è€…',
        'ã‚­ãƒ£ãƒªã‚¢ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼', 'CAï¼šID', 'CA_ID', 'æ±‚è·è€…ï¼šæ‹…å½“ãƒãƒ¼ãƒ '
    ])
    
    if ca_col:
        # é¢è«‡æ—¥ã‚«ãƒ©ãƒ ã‚’æ¢ã™ï¼ˆå®Ÿéš›ã®ã‚«ãƒ©ãƒ åã«åˆã‚ã›ã‚‹ï¼‰
        interview_date_col = find_column(df, [
            'æ±‚è·è€…ï¼šé¢è«‡æ—¥',  # å®Ÿéš›ã®ã‚«ãƒ©ãƒ å
            'é¢è«‡ï¼šé¢è«‡æ—¥', 'é¢è«‡æ—¥', 'é¢è«‡ï¼šæ—¥ä»˜', 'interview_date',
            'é¢è«‡ï¼šå®Ÿæ–½æ—¥', 'CAï¼šé¢è«‡æ—¥', 'æ±‚è·è€…ï¼šé›»è©±é¢è«‡æ—¥'
        ])
        
        if interview_date_col:
            df['é¢è«‡æ—¥_parsed'] = pd.to_datetime(df[interview_date_col], errors='coerce')
            valid_data = df[df['é¢è«‡æ—¥_parsed'].notna()]
        else:
            # é¢è«‡æ—¥ãŒãªãã¦ã‚‚ã€CAã”ã¨ã«é›†è¨ˆ
            valid_data = df
        
        ca_stats = valid_data.groupby(ca_col).agg({
            'æ±‚è·è€…ï¼šæ±‚è·è€…ID': 'nunique',
            'ä¼æ¥­ï¼šä¼æ¥­å': 'nunique'
        }).reset_index()
        
        ca_stats.columns = ['CAå', 'é¢è«‡æ•°', 'æ‹…å½“ä¼æ¥­æ•°']
        
        return ca_stats
    else:
        return pd.DataFrame()


def calculate_scouter_performance(df: pd.DataFrame, selected_companies=None, selected_months=None) -> pd.DataFrame:
    """
    ã‚¹ã‚«ã‚¦ã‚¿ãƒ¼ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
    """
    if df.empty:
        return pd.DataFrame()
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨
    df = apply_filters(df, selected_companies, selected_months)
    
    if df.empty:
        return pd.DataFrame()
    
    # ã‚¹ã‚«ã‚¦ã‚¿ãƒ¼ã‚«ãƒ©ãƒ ã‚’æ¢ã™ï¼ˆå®Ÿéš›ã®ã‚«ãƒ©ãƒ åã«åˆã‚ã›ã‚‹ï¼‰
    scouter_col = find_column(df, [
        'ã‚¹ã‚«ã‚¦ãƒˆæ‹…å½“è€…',  # å®Ÿéš›ã®ã‚«ãƒ©ãƒ å
        'ã‚¹ã‚«ã‚¦ã‚¿ãƒ¼ï¼šã‚¹ã‚«ã‚¦ã‚¿ãƒ¼å', 'ã‚¹ã‚«ã‚¦ã‚¿ãƒ¼å', 'ã‚¹ã‚«ã‚¦ã‚¿ãƒ¼ï¼šåå‰', 
        'ã‚¹ã‚«ã‚¦ã‚¿ãƒ¼', 'scouter_name', 'ã‚¹ã‚«ã‚¦ã‚¿ãƒ¼ï¼šæ‹…å½“è€…',
        'ã‚¹ã‚«ã‚¦ã‚¿ãƒ¼ï¼šID', 'ã‚¹ã‚«ã‚¦ã‚¿ãƒ¼_ID'
    ])
    
    if scouter_col:
        df['å†…å®šæ—¥_parsed'] = pd.to_datetime(df['é€²æ—ï¼šå†…å®šæ—¥'], errors='coerce')
        
        scouter_stats = []
        for scouter in df[scouter_col].dropna().unique():
            scouter_data = df[df[scouter_col] == scouter]
            
            ç´¹ä»‹æ•° = scouter_data['æ±‚è·è€…ï¼šæ±‚è·è€…ID'].nunique()
            æˆç´„æ•° = scouter_data['å†…å®šæ—¥_parsed'].notna().sum()
            æˆç´„ç‡ = (æˆç´„æ•° / ç´¹ä»‹æ•° * 100) if ç´¹ä»‹æ•° > 0 else 0.0
            
            # æ›¸é¡æå‡ºæ•°
            æ›¸é¡æå‡ºæ•° = scouter_data['é€²æ—ï¼šæ›¸é¡æå‡ºæ—¥'].notna().sum()
            æ›¸é¡æå‡ºç‡ = (æ›¸é¡æå‡ºæ•° / ç´¹ä»‹æ•° * 100) if ç´¹ä»‹æ•° > 0 else 0.0
            
            scouter_stats.append({
                'ã‚¹ã‚«ã‚¦ã‚¿ãƒ¼å': scouter,
                'ç´¹ä»‹æ•°': ç´¹ä»‹æ•°,
                'æ›¸é¡æå‡ºæ•°': æ›¸é¡æå‡ºæ•°,
                'æ›¸é¡æå‡ºç‡': æ›¸é¡æå‡ºç‡,
                'æˆç´„æ•°': æˆç´„æ•°,
                'æˆç´„ç‡': æˆç´„ç‡
            })
        
        return pd.DataFrame(scouter_stats)
    else:
        return pd.DataFrame()


def create_company_introduction_contract_chart(df: pd.DataFrame, selected_companies=None, selected_months=None, sort_by='ç´¹ä»‹æ•°', sort_order='é™é †', limit=10) -> go.Figure:
    """
    ä¼æ¥­ã”ã¨ã®ç´¹ä»‹ï½æˆç´„ç‡ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
    
    Parameters:
    - sort_by: ä¸¦ã³æ›¿ãˆåŸºæº– ('ç´¹ä»‹æ•°', 'æˆç´„æ•°', 'æˆç´„ç‡')
    - sort_order: ä¸¦ã³æ›¿ãˆé †åº ('æ˜‡é †', 'é™é †')
    - limit: è¡¨ç¤ºä»¶æ•°
    """
    stats_df = calculate_company_introduction_to_contract_rate(df, selected_companies, selected_months)
    
    if stats_df.empty:
        fig = go.Figure()
        fig.add_annotation(text="ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“", xref="paper", yref="paper", x=0.5, y=0.5, showarrow=False)
        return fig
    
    # ä¸¦ã³æ›¿ãˆ
    ascending = (sort_order == 'æ˜‡é †')
    if sort_by in stats_df.columns:
        stats_df = stats_df.sort_values(sort_by, ascending=ascending)
    
    # æŒ‡å®šä»¶æ•°ã‚’è¡¨ç¤º
    top_companies = stats_df.head(limit)
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        name='ç´¹ä»‹æ•°',
        x=top_companies['ä¼æ¥­å'],
        y=top_companies['ç´¹ä»‹æ•°'],
        marker_color='rgba(102, 126, 234, 0.7)',
        text=top_companies['ç´¹ä»‹æ•°'],
        textposition='outside'
    ))
    
    fig.add_trace(go.Bar(
        name='æˆç´„æ•°',
        x=top_companies['ä¼æ¥­å'],
        y=top_companies['æˆç´„æ•°'],
        marker_color='rgba(76, 175, 80, 0.7)',
        text=top_companies['æˆç´„æ•°'],
        textposition='outside'
    ))
    
    # æˆç´„ç‡ã‚’æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ã§è¿½åŠ 
    fig.add_trace(go.Scatter(
        name='æˆç´„ç‡',
        x=top_companies['ä¼æ¥­å'],
        y=top_companies['æˆç´„ç‡'],
        mode='lines+markers',
        yaxis='y2',
        line=dict(color='#ff6b6b', width=3),
        marker=dict(size=10)
    ))
    
    fig.update_layout(
        title='ğŸ“Š ä¼æ¥­ã”ã¨ã®ç´¹ä»‹ï½æˆç´„ç‡',
        xaxis_title='ä¼æ¥­å',
        yaxis_title='äººæ•°',
        yaxis2=dict(title='æˆç´„ç‡ (%)', overlaying='y', side='right'),
        barmode='group',
        height=500,
        template='plotly_white',
        xaxis=dict(tickangle=45)
    )
    
    return fig


def create_job_introduction_contract_chart(df: pd.DataFrame, selected_companies=None, selected_months=None, sort_by='ç´¹ä»‹æ•°', sort_order='é™é †', limit=15) -> go.Figure:
    """
    æ±‚äººã”ã¨ã®ç´¹ä»‹ï½æˆç´„ç‡ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
    
    Parameters:
    - sort_by: ä¸¦ã³æ›¿ãˆåŸºæº– ('ç´¹ä»‹æ•°', 'æˆç´„æ•°', 'æˆç´„ç‡')
    - sort_order: ä¸¦ã³æ›¿ãˆé †åº ('æ˜‡é †', 'é™é †')
    - limit: è¡¨ç¤ºä»¶æ•°
    """
    stats_df = calculate_job_introduction_to_contract_rate(df, selected_companies, selected_months)
    
    if stats_df.empty:
        fig = go.Figure()
        fig.add_annotation(text="ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“", xref="paper", yref="paper", x=0.5, y=0.5, showarrow=False)
        return fig
    
    # ä¸¦ã³æ›¿ãˆ
    ascending = (sort_order == 'æ˜‡é †')
    if sort_by in stats_df.columns:
        stats_df = stats_df.sort_values(sort_by, ascending=ascending)
    
    # æŒ‡å®šä»¶æ•°ã‚’è¡¨ç¤º
    top_jobs = stats_df.head(limit)
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        name='ç´¹ä»‹æ•°',
        x=top_jobs['æ±‚äººID'].astype(str),
        y=top_jobs['ç´¹ä»‹æ•°'],
        marker_color='rgba(102, 126, 234, 0.7)',
        text=top_jobs['ç´¹ä»‹æ•°'],
        textposition='outside'
    ))
    
    fig.add_trace(go.Bar(
        name='æˆç´„æ•°',
        x=top_jobs['æ±‚äººID'].astype(str),
        y=top_jobs['æˆç´„æ•°'],
        marker_color='rgba(76, 175, 80, 0.7)',
        text=top_jobs['æˆç´„æ•°'],
        textposition='outside'
    ))
    
    # æˆç´„ç‡ã‚’æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ã§è¿½åŠ 
    fig.add_trace(go.Scatter(
        name='æˆç´„ç‡',
        x=top_jobs['æ±‚äººID'].astype(str),
        y=top_jobs['æˆç´„ç‡'],
        mode='lines+markers',
        yaxis='y2',
        line=dict(color='#ff6b6b', width=3),
        marker=dict(size=10)
    ))
    
    fig.update_layout(
        title='ğŸ“Š æ±‚äººã”ã¨ã®ç´¹ä»‹ï½æˆç´„ç‡',
        xaxis_title='æ±‚äººID',
        yaxis_title='äººæ•°',
        yaxis2=dict(title='æˆç´„ç‡ (%)', overlaying='y', side='right'),
        barmode='group',
        height=500,
        template='plotly_white',
        xaxis=dict(tickangle=45)
    )
    
    return fig


def create_avg_recommendations_chart(df: pd.DataFrame, selected_companies=None, selected_months=None) -> go.Figure:
    """
    æ±‚è·è€…1äººå½“ãŸã‚Šã®å¹³å‡æ¨è–¦æ•°ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
    """
    stats = calculate_avg_recommendations_per_candidate(df, selected_companies, selected_months)
    
    if stats['total_candidates'] == 0:
        fig = go.Figure()
        fig.add_annotation(text="ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“", xref="paper", yref="paper", x=0.5, y=0.5, showarrow=False)
        return fig
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨ï¼ˆã‚°ãƒ©ãƒ•è¡¨ç¤ºç”¨ï¼‰
    filtered_df = apply_filters(df, selected_companies, selected_months)
    
    # ä¼æ¥­ã”ã¨ã®å¹³å‡æ¨è–¦æ•°ã‚’è¨ˆç®—
    company_stats = []
    for company in filtered_df['ä¼æ¥­ï¼šä¼æ¥­å'].unique():
        company_data = filtered_df[filtered_df['ä¼æ¥­ï¼šä¼æ¥­å'] == company]
        candidates = company_data['æ±‚è·è€…ï¼šæ±‚è·è€…ID'].nunique()
        recommendations = len(company_data)
        avg = recommendations / candidates if candidates > 0 else 0
        
        company_stats.append({
            'ä¼æ¥­å': company,
            'å¹³å‡æ¨è–¦æ•°': avg,
            'æ±‚è·è€…æ•°': candidates,
            'æ¨è–¦æ•°': recommendations
        })
    
    company_df = pd.DataFrame(company_stats)
    top_companies = company_df.nlargest(10, 'å¹³å‡æ¨è–¦æ•°')
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        x=top_companies['ä¼æ¥­å'],
        y=top_companies['å¹³å‡æ¨è–¦æ•°'],
        marker=dict(
            color=top_companies['å¹³å‡æ¨è–¦æ•°'],
            colorscale='Viridis',
            showscale=True,
            colorbar=dict(title="å¹³å‡æ¨è–¦æ•°")
        ),
        text=[f"{val:.2f}" for val in top_companies['å¹³å‡æ¨è–¦æ•°']],
        textposition='outside'
    ))
    
    fig.update_layout(
        title=f'ğŸ“Š æ±‚è·è€…1äººå½“ãŸã‚Šã®å¹³å‡æ¨è–¦æ•°ï¼ˆå…¨ä½“å¹³å‡: {stats["avg_recommendations"]:.2f}ï¼‰',
        xaxis_title='ä¼æ¥­å',
        yaxis_title='å¹³å‡æ¨è–¦æ•°',
        height=500,
        template='plotly_white',
        xaxis=dict(tickangle=45)
    )
    
    return fig


def create_leadtime_chart(df: pd.DataFrame, selected_companies=None, selected_months=None) -> go.Figure:
    """
    é¢è«‡ã‹ã‚‰æ¨è–¦ã¾ã§ã®ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
    """
    stats_df = calculate_interview_to_recommendation_leadtime(df, selected_companies, selected_months)
    
    if stats_df.empty:
        fig = go.Figure()
        fig.add_annotation(
            text="é¢è«‡æ—¥ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã€Œæ±‚è·è€…ï¼šé¢è«‡æ—¥ã€ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
            xref="paper", yref="paper", x=0.5, y=0.5, showarrow=False
        )
        return fig
    
    # ä¸Šä½10ç¤¾ã‚’è¡¨ç¤º
    top_companies = stats_df.nlargest(10, 'ä»¶æ•°')
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        x=top_companies['ä¼æ¥­å'],
        y=top_companies['å¹³å‡ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ '],
        marker=dict(
            color=top_companies['å¹³å‡ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ '],
            colorscale='Reds',
            showscale=True,
            colorbar=dict(title="å¹³å‡ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ  (æ—¥)")
        ),
        text=[f"{val:.1f}æ—¥" for val in top_companies['å¹³å‡ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ']],
        textposition='outside'
    ))
    
    fig.update_layout(
        title='â±ï¸ é¢è«‡ã‹ã‚‰æ¨è–¦ã¾ã§ã®ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ï¼ˆä¼æ¥­åˆ¥ï¼‰',
        xaxis_title='ä¼æ¥­å',
        yaxis_title='å¹³å‡ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ  (æ—¥)',
        height=500,
        template='plotly_white',
        xaxis=dict(tickangle=45)
    )
    
    return fig


def create_ca_interviews_chart(df: pd.DataFrame, selected_companies=None, selected_months=None) -> go.Figure:
    """
    é¢è«‡æ•°ï¼ˆCAã”ã¨ï¼‰ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
    """
    stats_df = calculate_interviews_by_ca(df, selected_companies, selected_months)
    
    if stats_df.empty:
        fig = go.Figure()
        fig.add_annotation(
            text="CAãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã€Œæ±‚è·è€…ï¼šæ‹…å½“è€…ã€ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
            xref="paper", yref="paper", x=0.5, y=0.5, showarrow=False
        )
        return fig
    
    # é¢è«‡æ•°ã§ã‚½ãƒ¼ãƒˆ
    stats_df = stats_df.sort_values('é¢è«‡æ•°', ascending=False)
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        x=stats_df['CAå'],
        y=stats_df['é¢è«‡æ•°'],
        marker=dict(
            color=stats_df['é¢è«‡æ•°'],
            colorscale='Blues',
            showscale=True,
            colorbar=dict(title="é¢è«‡æ•°")
        ),
        text=stats_df['é¢è«‡æ•°'],
        textposition='outside'
    ))
    
    fig.update_layout(
        title='ğŸ‘¥ é¢è«‡æ•°ï¼ˆCAã”ã¨ï¼‰',
        xaxis_title='CAå',
        yaxis_title='é¢è«‡æ•°',
        height=500,
        template='plotly_white',
        xaxis=dict(tickangle=45)
    )
    
    return fig


def create_scouter_performance_chart(df: pd.DataFrame, selected_companies=None, selected_months=None) -> go.Figure:
    """
    ã‚¹ã‚«ã‚¦ã‚¿ãƒ¼ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
    """
    stats_df = calculate_scouter_performance(df, selected_companies, selected_months)
    
    if stats_df.empty:
        fig = go.Figure()
        fig.add_annotation(
            text="ã‚¹ã‚«ã‚¦ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã€Œã‚¹ã‚«ã‚¦ãƒˆæ‹…å½“è€…ã€ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
            xref="paper", yref="paper", x=0.5, y=0.5, showarrow=False
        )
        return fig
    
    # ç´¹ä»‹æ•°ã§ã‚½ãƒ¼ãƒˆ
    stats_df = stats_df.sort_values('ç´¹ä»‹æ•°', ascending=False)
    
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('ç´¹ä»‹æ•°', 'æˆç´„ç‡', 'æ›¸é¡æå‡ºç‡', 'æˆç´„æ•°'),
        specs=[[{"type": "bar"}, {"type": "bar"}],
               [{"type": "bar"}, {"type": "bar"}]]
    )
    
    # ç´¹ä»‹æ•°
    fig.add_trace(
        go.Bar(x=stats_df['ã‚¹ã‚«ã‚¦ã‚¿ãƒ¼å'], y=stats_df['ç´¹ä»‹æ•°'], marker_color='rgba(102, 126, 234, 0.7)'),
        row=1, col=1
    )
    
    # æˆç´„ç‡
    fig.add_trace(
        go.Bar(x=stats_df['ã‚¹ã‚«ã‚¦ã‚¿ãƒ¼å'], y=stats_df['æˆç´„ç‡'], marker_color='rgba(76, 175, 80, 0.7)'),
        row=1, col=2
    )
    
    # æ›¸é¡æå‡ºç‡
    fig.add_trace(
        go.Bar(x=stats_df['ã‚¹ã‚«ã‚¦ã‚¿ãƒ¼å'], y=stats_df['æ›¸é¡æå‡ºç‡'], marker_color='rgba(255, 152, 0, 0.7)'),
        row=2, col=1
    )
    
    # æˆç´„æ•°
    fig.add_trace(
        go.Bar(x=stats_df['ã‚¹ã‚«ã‚¦ã‚¿ãƒ¼å'], y=stats_df['æˆç´„æ•°'], marker_color='rgba(156, 39, 176, 0.7)'),
        row=2, col=2
    )
    
    fig.update_layout(
        title='ğŸ¯ ã‚¹ã‚«ã‚¦ã‚¿ãƒ¼ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š',
        height=700,
        template='plotly_white',
        showlegend=False
    )
    
    fig.update_xaxes(tickangle=45, row=1, col=1)
    fig.update_xaxes(tickangle=45, row=1, col=2)
    fig.update_xaxes(tickangle=45, row=2, col=1)
    fig.update_xaxes(tickangle=45, row=2, col=2)
    
    fig.update_yaxes(title_text="äººæ•°", row=1, col=1)
    fig.update_yaxes(title_text="ç‡ (%)", row=1, col=2)
    fig.update_yaxes(title_text="ç‡ (%)", row=2, col=1)
    fig.update_yaxes(title_text="äººæ•°", row=2, col=2)
    
    return fig 